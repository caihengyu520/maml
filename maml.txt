《Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks》
该论文主要是提出了一种网络模型权重初始化方法以及使其能够快速适应于新的任务，其核心思想是通过在一系列任务上进行训练验证从而能够得出模型中对损失最为敏感的参数从而能够通过少量梯度下降更新步骤快速适应新的任务而不会过度拟合。

区别于之前的大多数小样本，元学习算法
小样本学习：孪生网络，匹配网络，记忆增强型网络，LSTM优化器网络，learning to learn by gradient through gradient

但是这里是计算双重梯度，而learning to learn并非是计算双重梯度，而只是说通过不同的梯度计算方式来得出一种元优化器去优化基本优化器。该方法在分类，回归以及强化学习上面都得到实验验证，并证明了其结果性能。

元学习阶段，首先是从任务中取样支持集进行训练，更新参数副本，然后等到支持集训练结束后，利用测试集进行参数更新，更新元学习器参数。然后重复之前的行为。当模型训练成功后，遇到新任务时，直接将元学习器的参数当作基本模型参数，然后执行梯度下降算法进行更新，这样性能会更优，并且不会容易陷入过拟合，十分适合小样本的更新集。 该算法主要的计算耗时在于可能需要进行二阶导数计算，但是通过实验证明，即使使用一阶梯度计算，其结果相对二阶梯度反向传播，结果并不会差很多，基本上在能够接受的范围内。具体算法见论文链接：https://arxiv.org/abs/1703.03400